# MLOps - Proyecto de OperacionalizaciÃ³n de Machine Learning

**Proyecto final presentado en la materia MLOps - OperacionalizaciÃ³n de Machine Learning en el Master Deep Learning en la UPM**

![Python](https://img.shields.io/badge/python-v3.9+-blue.svg)
![Docker](https://img.shields.io/badge/docker-enabled-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#descripciÃ³n)
- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Requisitos](#requisitos)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Uso](#uso)
- [Interfaz NLP](#interfaz-nlp)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Despliegue](#despliegue)
- [ContribuciÃ³n](#contribuciÃ³n)
- [Licencia](#licencia)

## ğŸ“– DescripciÃ³n

Este proyecto implementa un pipeline completo de MLOps para el procesamiento y anÃ¡lisis de texto utilizando tÃ©cnicas de Natural Language Processing (NLP). El objetivo es demostrar las mejores prÃ¡cticas en la operacionalizaciÃ³n de modelos de Machine Learning, incluyendo:

- Desarrollo y entrenamiento de modelos NLP
- ContainerizaciÃ³n con Docker
- CI/CD con GitHub Actions
- Monitoreo y logging
- API REST para inferencia
- Interfaz de usuario interactiva

## âœ¨ CaracterÃ­sticas

- ğŸ¤– **Modelos NLP**: ImplementaciÃ³n de modelos para anÃ¡lisis de sentimientos, clasificaciÃ³n de texto y mÃ¡s
- ğŸ”„ **Pipeline automatizado**: Flujo completo desde entrenamiento hasta despliegue
- ğŸ³ **ContainerizaciÃ³n**: AplicaciÃ³n dockerizada para fÃ¡cil despliegue
- ğŸš€ **CI/CD**: IntegraciÃ³n y despliegue continuo con GitHub Actions
- ğŸ“Š **Monitoreo**: Logging y mÃ©tricas de rendimiento
- ğŸŒ **API REST**: Endpoints para inferencia de modelos
- ğŸ’» **Interfaz grÃ¡fica**: Interfaz de usuario amigable para interactuar con los modelos

## ğŸ› ï¸ Requisitos

### Requisitos del Sistema
- Python 3.9+
- Docker
- Git

### Dependencias principales
- FastAPI
- scikit-learn
- pandas
- numpy
- streamlit (para la interfaz)
- uvicorn

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/iamam07/MLOps.git
cd MLOps
```

### 2. Crear entorno virtual
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Configurar variables de entorno
```bash
cp .env.example .env
# Editar .env con tus configuraciones especÃ­ficas
```

## ğŸ’¡ Uso

### EjecuciÃ³n local
```bash
# Iniciar el servidor API
python main.py

# Iniciar la interfaz NLP (en otra terminal)
python interfaceNLP.py
```

### Con Docker
```bash
# Construir la imagen
docker build -t mlops-app .

# Ejecutar el contenedor
docker run -p 8000:8000 -p 8501:8501 mlops-app
```

## ğŸ¯ Interfaz para Simitud

La interfaz proporciona una interfaz grÃ¡fica interactiva para trabajar con un modelos de procesamiento de lenguaje natural exactamente en temas de Similitud SemÃ¡ntica entre dos oraciones.

Nota: A pesar de que la interface esta preparada para otras funciones, en esta version solo esta disponible la opcion de Similitud SemÃ¡ntica la cual se puede seleccionar en la opcion lateral donde tambien existen otras opciones disponible.

### CaracterÃ­sticas de la Interfaz

- **Similitud SemÃ¡ntica**: Determina el nivel de Similitud SemÃ¡ntica entre dos oraciones.

### GuÃ­a de Uso de la Interfaz

#### 1. Iniciar la Interfaz
```bash
python interfaceNLP.py
```
La interfaz se abrirÃ¡ automÃ¡ticamente en tu navegador en `http://localhost:8501`

#### 2. AnÃ¡lisis de Texto Individual

1. **Selecciona el tipo de opcion** en el menÃº desplegable lateral:
   - Similitud SemÃ¡ntica

#### 3. Procesamiento de las oraciones 

1. **Indicar las Oraciones** completa los campos correspondiente a las dos oraciones a la que se le estara realizando la Similitud SemÃ¡ntica.

2. **Ejecuta la Comparacion** y se desplegara en la parte de arriba como si fuera un chat el resultado de la comparacion semantica de ambas oraciones.


#### 4. ConfiguraciÃ³n Avanzada

- **Ajustar umbral de confianza**: Modifica el nivel mÃ­nimo de confianza para las predicciones
- **Seleccionar idioma**: Cambia el idioma de procesamiento
- **Personalizar salida**: Elige el formato de los resultados exportados


## ğŸ“ Estructura del Proyecto

```
MLOps/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ endpoints.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ logging.py
â”‚   â””â”€â”€ ml/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ models.py
â”‚       â”œâ”€â”€ preprocessing.py
â”‚       â””â”€â”€ training.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â”œâ”€â”€ interfaceNLP.py
â””â”€â”€ README.md
```

## ğŸš€ Despliegue

### GitHub Actions CI/CD

El proyecto incluye un pipeline de CI/CD que:

1. **Ejecuta tests** automÃ¡ticamente en cada push
2. **Construye la imagen Docker** 
3. **Despliega a GitHub Container Registry**
4. **Actualiza el entorno de producciÃ³n**

### Despliegue Manual

```bash
# Construir y tagear la imagen
docker build -t ghcr.io/iamam07/mlops-app:latest .

# Subir al registro
docker push ghcr.io/iamam07/mlops-app:latest

# Desplegar en producciÃ³n
docker run -d -p 8000:8000 -p 8501:8501 ghcr.io/iamam07/mlops-app:latest
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

```bash
# .env
API_HOST=0.0.0.0
API_PORT=8000
MODEL_PATH=./data/models/
LOG_LEVEL=INFO
ENVIRONMENT=production
```

### ConfiguraciÃ³n de Modelos

Los modelos se configuran en `app/core/config.py`:

```python
MODELS_CONFIG = {
    "sentiment_analysis": {
        "model_path": "models/sentiment_model.pkl",
        "threshold": 0.7
    }
}
```

## ğŸ¤ ContribuciÃ³n

1. **Fork** el proyecto
2. **Crea** una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. **Push** a la rama (`git push origin feature/AmazingFeature`)
5. **Abre** un Pull Request

### EstÃ¡ndares de CÃ³digo

- Usar **Black** para formateo
- Seguir **PEP 8**
- Incluir **docstrings** en todas las funciones
- Escribir **tests** para nuevas funcionalidades

## ğŸ“Š MÃ©tricas y Monitoreo

El proyecto incluye:

- **Logging estructurado** con diferentes niveles
- **MÃ©tricas de rendimiento** de los modelos
- **Monitoreo de salud** de la API
- **Alertas** por email en caso de fallos

## ğŸ”— Enlaces Ãštiles

- [DocumentaciÃ³n de FastAPI](https://fastapi.tiangolo.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Docker Documentation](https://docs.docker.com/)
- [MLOps Best Practices](https://ml-ops.org/)

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¨â€ğŸ’» Autor

**Miguel A. Martinez** - *Proyecto Final MLOps*
- GitHub: [@iamam07](https://github.com/iamam07)
- LinkedIn: [Tu perfil de LinkedIn]



â­ **Â¡Si este proyecto te resulta Ãºtil, considera darle una estrella!** â­