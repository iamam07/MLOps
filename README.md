# MLOps - Proyecto de OperacionalizaciÃ³n de Machine Learning

**Proyecto final presentado en la materia MLOps - OperacionalizaciÃ³n de Machine Learning en el Master Deep Learning en la UPM**

![Python](https://img.shields.io/badge/python-v3.9+-blue.svg)
![Docker](https://img.shields.io/badge/docker-enabled-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#descripciÃ³n)
- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Requisitos](#requisitos)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Uso](#uso)
- [Interfaz NLP](#interfaz-nlp)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Despliegue](#despliegue)
- [ContribuciÃ³n](#contribuciÃ³n)
- [Licencia](#licencia)

## ğŸ“– DescripciÃ³n

Este proyecto implementa un pipeline completo de MLOps para el procesamiento y anÃ¡lisis de texto utilizando tÃ©cnicas de Natural Language Processing (NLP). El objetivo es demostrar las mejores prÃ¡cticas en la operacionalizaciÃ³n de modelos de Machine Learning, incluyendo:

- Desarrollo y entrenamiento de modelos NLP
- ContainerizaciÃ³n con Docker
- CI/CD con GitHub Actions
- Monitoreo y logging
- API REST para inferencia
- Interfaz de usuario interactiva

## âœ¨ CaracterÃ­sticas

- ğŸ¤– **Modelos NLP**: ImplementaciÃ³n de modelos para anÃ¡lisis de sentimientos, clasificaciÃ³n de texto y mÃ¡s
- ğŸ”„ **Pipeline automatizado**: Flujo completo desde entrenamiento hasta despliegue
- ğŸ³ **ContainerizaciÃ³n**: AplicaciÃ³n dockerizada para fÃ¡cil despliegue
- ğŸš€ **CI/CD**: IntegraciÃ³n y despliegue continuo con GitHub Actions
- ğŸ“Š **Monitoreo**: Logging y mÃ©tricas de rendimiento
- ğŸŒ **API REST**: Endpoints para inferencia de modelos
- ğŸ’» **Interfaz grÃ¡fica**: Interfaz de usuario amigable para interactuar con los modelos

## ğŸ› ï¸ Requisitos

### Requisitos del Sistema
- Python 3.9+
- Docker
- Git

### Dependencias principales
- FastAPI
- scikit-learn
- pandas
- numpy
- streamlit (para la interfaz)
- uvicorn

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/iamam07/MLOps.git
cd MLOps
```

### 2. Crear entorno virtual
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Configurar variables de entorno
```bash
cp .env.example .env
# Editar .env con tus configuraciones especÃ­ficas
```

## ğŸ’¡ Uso

### EjecuciÃ³n local
```bash
# Iniciar el servidor API
python main.py

# Iniciar la interfaz NLP (en otra terminal)
python interfaceNLP.py
```

### Con Docker
```bash
# Construir la imagen
docker build -t mlops-app .

# Ejecutar el contenedor
docker run -p 8000:8000 -p 8501:8501 mlops-app
```

## ğŸ¯ Interfaz NLP

La interfaz NLP (`interfaceNLP.py`) proporciona una interfaz grÃ¡fica interactiva para trabajar con los modelos de procesamiento de lenguaje natural.

### CaracterÃ­sticas de la Interfaz

- **AnÃ¡lisis de Sentimientos**: Determina si un texto es positivo, negativo o neutral
- **ClasificaciÃ³n de Texto**: Clasifica textos en categorÃ­as predefinidas
- **Procesamiento en Lote**: Carga y procesa mÃºltiples textos desde archivos
- **VisualizaciÃ³n de Resultados**: GrÃ¡ficos y mÃ©tricas de los anÃ¡lisis realizados

### GuÃ­a de Uso de la Interfaz

#### 1. Iniciar la Interfaz
```bash
python interfaceNLP.py
```
La interfaz se abrirÃ¡ automÃ¡ticamente en tu navegador en `http://localhost:8501`

#### 2. AnÃ¡lisis de Texto Individual

1. **Selecciona el tipo de anÃ¡lisis** en el menÃº desplegable:
   - AnÃ¡lisis de Sentimientos
   - ClasificaciÃ³n de Texto
   - ExtracciÃ³n de Entidades

2. **Ingresa tu texto** en el Ã¡rea de texto proporcionada

3. **Haz clic en "Analizar"** para obtener los resultados

4. **Visualiza los resultados** que incluyen:
   - PredicciÃ³n del modelo
   - Confianza de la predicciÃ³n
   - GrÃ¡ficos de probabilidades

#### 3. Procesamiento en Lote

1. **Ve a la secciÃ³n "Procesamiento en Lote"**

2. **Carga tu archivo** (formatos soportados: .txt, .csv, .json):
   ```
   Ejemplo de formato CSV:
   texto,etiqueta_real
   "Me encanta este producto",positivo
   "No me gusta nada",negativo
   ```

3. **Selecciona las columnas** relevantes si es un CSV

4. **Ejecuta el anÃ¡lisis** y descarga los resultados

#### 4. ComparaciÃ³n de Modelos

1. **Accede a la secciÃ³n "ComparaciÃ³n"**

2. **Selecciona mÃºltiples modelos** para comparar

3. **Ingresa el texto de prueba**

4. **Compara los resultados** lado a lado con mÃ©tricas de rendimiento

#### 5. ConfiguraciÃ³n Avanzada

- **Ajustar umbral de confianza**: Modifica el nivel mÃ­nimo de confianza para las predicciones
- **Seleccionar idioma**: Cambia el idioma de procesamiento
- **Personalizar salida**: Elige el formato de los resultados exportados

### Ejemplos de Uso

#### AnÃ¡lisis de Sentimientos
```python
# Texto de ejemplo
texto = "Â¡Excelente servicio! Muy recomendado."

# Resultado esperado
{
    "sentimiento": "positivo",
    "confianza": 0.95,
    "probabilidades": {
        "positivo": 0.95,
        "neutral": 0.04,
        "negativo": 0.01
    }
}
```

#### ClasificaciÃ³n de Texto
```python
# Texto de ejemplo
texto = "Â¿CuÃ¡l es el horario de atenciÃ³n al cliente?"

# Resultado esperado
{
    "categoria": "soporte_cliente",
    "confianza": 0.87,
    "subcategorias": ["horarios", "informacion_general"]
}
```

### SoluciÃ³n de Problemas

#### Error de ConexiÃ³n
- Verifica que el servidor API estÃ© ejecutÃ¡ndose en `http://localhost:8000`
- Revisa que no haya conflictos de puertos

#### Rendimiento Lento
- Reduce el tamaÃ±o del lote de procesamiento
- Verifica los recursos disponibles del sistema

#### Errores de Formato
- AsegÃºrate de que los archivos tengan la codificaciÃ³n UTF-8
- Verifica que el formato del CSV sea correcto

## ğŸ“ Estructura del Proyecto

```
MLOps/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ endpoints.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ logging.py
â”‚   â””â”€â”€ ml/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ models.py
â”‚       â”œâ”€â”€ preprocessing.py
â”‚       â””â”€â”€ training.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â”œâ”€â”€ interfaceNLP.py
â””â”€â”€ README.md
```

## ğŸš€ Despliegue

### GitHub Actions CI/CD

El proyecto incluye un pipeline de CI/CD que:

1. **Ejecuta tests** automÃ¡ticamente en cada push
2. **Construye la imagen Docker** 
3. **Despliega a GitHub Container Registry**
4. **Actualiza el entorno de producciÃ³n**

### Despliegue Manual

```bash
# Construir y tagear la imagen
docker build -t ghcr.io/iamam07/mlops-app:latest .

# Subir al registro
docker push ghcr.io/iamam07/mlops-app:latest

# Desplegar en producciÃ³n
docker run -d -p 8000:8000 -p 8501:8501 ghcr.io/iamam07/mlops-app:latest
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

```bash
# .env
API_HOST=0.0.0.0
API_PORT=8000
MODEL_PATH=./data/models/
LOG_LEVEL=INFO
ENVIRONMENT=production
```

### ConfiguraciÃ³n de Modelos

Los modelos se configuran en `app/core/config.py`:

```python
MODELS_CONFIG = {
    "sentiment_analysis": {
        "model_path": "models/sentiment_model.pkl",
        "threshold": 0.7
    },
    "text_classification": {
        "model_path": "models/classifier_model.pkl",
        "categories": ["categoria1", "categoria2", "categoria3"]
    }
}
```

## ğŸ¤ ContribuciÃ³n

1. **Fork** el proyecto
2. **Crea** una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. **Push** a la rama (`git push origin feature/AmazingFeature`)
5. **Abre** un Pull Request

### EstÃ¡ndares de CÃ³digo

- Usar **Black** para formateo
- Seguir **PEP 8**
- Incluir **docstrings** en todas las funciones
- Escribir **tests** para nuevas funcionalidades

## ğŸ“Š MÃ©tricas y Monitoreo

El proyecto incluye:

- **Logging estructurado** con diferentes niveles
- **MÃ©tricas de rendimiento** de los modelos
- **Monitoreo de salud** de la API
- **Alertas** por email en caso de fallos

## ğŸ”— Enlaces Ãštiles

- [DocumentaciÃ³n de FastAPI](https://fastapi.tiangolo.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Docker Documentation](https://docs.docker.com/)
- [MLOps Best Practices](https://ml-ops.org/)

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¨â€ğŸ’» Autor

**AndrÃ©s MejÃ­a** - *Proyecto Final MLOps*
- GitHub: [@iamam07](https://github.com/iamam07)
- LinkedIn: [Tu perfil de LinkedIn]

## ğŸ™ Agradecimientos

- Universidad PolitÃ©cnica de Madrid (UPM)
- Master en Deep Learning
- Profesores y compaÃ±eros del programa MLOps

---

â­ **Â¡Si este proyecto te resulta Ãºtil, considera darle una estrella!** â­