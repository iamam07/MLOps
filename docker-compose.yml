services:
  # trainer:
  #   build:
  #     context: ./project
  #     dockerfile: Dockerfile.trainer
  #   command: python train.py
  #   volumes:
  #     - ./model_storage:/mnt/model
  #   environment:
  #     - OUTPUT_MODEL_PATH=/mnt/model/best_model.pt
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   runtime: nvidia

  app:
    build:
      context: ./project
      dockerfile: Dockerfile.app
    command: uvicorn app:app --host 0.0.0.0 --port 8005
    ports:
      - "8005:8005"
    volumes:
      - ./model_storage:/mnt/model
    environment:
      - MODEL_PATH=/mnt/model/best_model.pt
    depends_on:
      - trainer

  interface:
    build:
      context: ./project
      dockerfile: Dockerfile.interface
    command: streamlit run interfaceNLP.py --server.port 8501 --server.address 0.0.0.0
    ports:
      - "8501:8501"
    depends_on:
      - app
